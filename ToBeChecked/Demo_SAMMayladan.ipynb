{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/geoaigroup/Aerial-SAM/blob/main/AerialSAM_GEOAI_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMt23BhFL5La"
   },
   "source": [
    "## SAM Online Demo: Segment everything Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4a4b25c"
   },
   "source": [
    "The Segment Anything Model (SAM) predicts object masks given prompts that indicate the desired object.\n",
    "\n",
    "Please go tho this link:\n",
    "https://segment-anything.com/demo\n",
    "\n",
    "And use this image as input:\n",
    "https://github.com/geoaigroup/Aerial-SAM/blob/main/483.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "644532a8"
   },
   "source": [
    "## Environment Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07fabfee"
   },
   "source": [
    "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXi87ep3DNxC"
   },
   "outputs": [],
   "source": [
    "#Samples used in this demo are from the WHU Building Dataset: https://paperswithcode.com/dataset/whu-building-dataset\n",
    "# !wget https://github.com/geoaigroup/Aerial-SAM/raw/main/resources/data.zip\n",
    "# !wget https://github.com/geoaigroup/Aerial-SAM/raw/main/resources/pred_shapefile.zip\n",
    "# !unzip data.zip\n",
    "# !unzip pred_shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ea65efc"
   },
   "outputs": [],
   "source": [
    "# using_colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91dd9a89"
   },
   "outputs": [],
   "source": [
    "# if using_colab:\n",
    "#     import torch\n",
    "#     import torchvision\n",
    "#     print(\"PyTorch version:\", torch.__version__)\n",
    "#     print(\"Torchvision version:\", torchvision.__version__)\n",
    "#     print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "#     import sys\n",
    "#     !{sys.executable} -m pip install opencv-python matplotlib\n",
    "#     !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "\n",
    "#     !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "#     !pip install geopandas\n",
    "#     !pip install rasterio\n",
    "#     !git clone https://github.com/geoaigroup/buildingsSAM.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69b28288"
   },
   "outputs": [],
   "source": [
    "#Necessary imports and helper functions for displaying points, boxes, and masks.\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import shapely.geometry as sg\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Point, Polygon\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "#from metrics import DiceScore,IoUScore\n",
    "import pandas as pd\n",
    "import gc\n",
    "import shutil\n",
    "import fiona\n",
    "import json\n",
    "\n",
    "import utils\n",
    "from evaluate import cal_scores,matching_algorithm\n",
    "from pred_SAM import SAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6yDAdyql7lf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cal_score(gt_tile, pred_tile):\n",
    "    matcher = matching_algorithm(gt_tile, pred_tile)\n",
    "    iou_list, f1_scores, tp_pred_indices, tp_gt_indices, fp_indices, fn_indices, mscores, precision, recall = matcher.matching()\n",
    "    tp_iou_list, avg_tp_iou = matcher.tp_iou(tp_pred_indices, tp_gt_indices)\n",
    "    score = {}\n",
    "    scores_b = []\n",
    "    score['iou_list'] = iou_list\n",
    "    score['f1_scores'] = f1_scores\n",
    "    score['tp_iou_list'] = tp_iou_list\n",
    "    score['fp_indices'] = fp_indices\n",
    "    score['fn_indices'] = fn_indices\n",
    "    score['Mean_iou'] = np.mean(iou_list, dtype=float)\n",
    "    score['Mean_f1'] = np.mean(f1_scores, dtype=float)\n",
    "    score['avg_tp_iou'] = float(avg_tp_iou) if avg_tp_iou != None else 0.0\n",
    "    score['precision'] = precision\n",
    "    score['recall'] = recall\n",
    "\n",
    "    for s in mscores:\n",
    "        scores_b.append(s)\n",
    "    scores_b.append(score)\n",
    "\n",
    "    gtmask=np.zeros((512,512))\n",
    "    predmask=np.zeros((512,512))\n",
    "    for g in gt_tile:\n",
    "        gtmask=g+gtmask\n",
    "    for p in pred_tile:\n",
    "        predmask=p+predmask\n",
    "    fig,ax = plt.subplots(1,2,figsize = (10,10))\n",
    "    ax = ax.ravel()\n",
    "    ax[0].imshow(gtmask)\n",
    "    ax[0].set_title(\"GT\")\n",
    "    ax[1].imshow(predmask)\n",
    "    ax[1].set_title(\"MultiClassUnet CNN\")\n",
    "    plt.show()\n",
    "\n",
    "    return scores_b\n",
    "\n",
    "def Calculate_CNN_Results():\n",
    "    ff = gpd.read_file(pred)\n",
    "    score_list = []\n",
    "\n",
    "    ids = [f for f in os.listdir(orig_shp)]\n",
    "\n",
    "    for name in tqdm(ids):\n",
    "        print(name)\n",
    "        if glob.glob(score_dir + \"/\" + name + \"_score.json\" ):\n",
    "            print(\"Found\")\n",
    "            continue\n",
    "        if name in os.listdir(orig_shp):\n",
    "            try:\n",
    "                gt = gpd.read_file(orig_shp + \"/\" + name)\n",
    "                if len(gt[\"geometry\"]) == 0:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        predic = ff.loc[ff[\"ImageId\"] == name]\n",
    "        n=name.split('.')[0]\n",
    "        if len(predic[\"geometry\"]) == 0:\n",
    "            continue\n",
    "\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        gt_tile = []\n",
    "        pred_tile=[]\n",
    "\n",
    "        gt_tile=utils.convert_polygon_to_mask_batch(gt['geometry'])\n",
    "        pred_tile=utils.convert_polygon_to_mask_batch(predic[\"geometry\"])\n",
    "\n",
    "        scores_res=cal_score(gt_tile, pred_tile)\n",
    "        os.makedirs(score_dir, exist_ok=True)\n",
    "\n",
    "        with open(score_dir + f'/{name}_score.json', 'w') as f1:\n",
    "            json.dump(scores_res, f1)\n",
    "\n",
    "    scores=cal_scores(output_dir,score_dir)\n",
    "    scores.macro_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTMYJz817o2c"
   },
   "outputs": [],
   "source": [
    "def main(CNN=\"\",prompt_type=\"\",sam=None):\n",
    "    score_list = []\n",
    "    scores=cal_scores(output_dir,score_dir)\n",
    "    # ff = gpd.read_file(pred)\n",
    "    ids = [f for f in os.listdir(pred)]\n",
    "    for name in tqdm(ids):\n",
    "        print(name)\n",
    "        print(\"Checking\")\n",
    "        flag=0\n",
    "        if glob.glob(output_dir + \"/\" + name + \"/\" + name + \".shp\" ) or glob.glob(output_dir + \"/\" + name + \"/\" + name + \".png\" ):\n",
    "            print(\"Found\")\n",
    "            continue\n",
    "\n",
    "        tile_boxes = []\n",
    "        image_data=None\n",
    "        try:\n",
    "            # image = cv2.imread(images + \"/\" + name+'.tif')\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            with rasterio.open(images + \"/\" + name+'.tif') as src:\n",
    "                # Read the image data\n",
    "                image_data = src.read()\n",
    "                transform=src.transform\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(name)\n",
    "\n",
    "        # if name in os.listdir(orig_shp):\n",
    "        #         gt = gpd.read_file(orig_shp + \"/\" + name)\n",
    "        #         if len(gt[\"geometry\"]) == 0:\n",
    "        #             continue\n",
    "        # else:\n",
    "        #     continue\n",
    "        if CNN==\"multiclassUnet\":\n",
    "\n",
    "            # predic = ff.loc[ff[\"ImageId\"] == name]\n",
    "            predic = gpd.read_file(pred+\"/\"+name)\n",
    "        elif CNN==\"DCNN\":\n",
    "            predic = gpd.read_file(pred+\"/\"+name)\n",
    "\n",
    "        geo = predic[\"geometry\"]\n",
    "\n",
    "        if len(geo) == 0:\n",
    "            continue\n",
    "\n",
    "        input_point=None\n",
    "        input_label=None\n",
    "        input_boxes=None\n",
    "         \n",
    "        match prompt_type:\n",
    "            case \"single point\":\n",
    "                input_point,input_label=utils.create_list_points(geo,name)\n",
    "            case \"single + negative points\":\n",
    "                input_point,input_label=utils.create_list_points(geo,name,flag=\"negative\")\n",
    "                print(input_point)\n",
    "                print(input_label)\n",
    "            #Skeleton\n",
    "            case \"skeleton\":\n",
    "                input_point=[]\n",
    "                input_label=[]\n",
    "                with open(skeleton_points, 'r') as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                matching_items = []\n",
    "                for item in data:\n",
    "                    if item['id'] == name:\n",
    "                        matching_items.append(item)\n",
    "\n",
    "                input_point=torch.Tensor(matching_items[0]['input_points']).cuda()\n",
    "                input_label=torch.Tensor(matching_items[0]['input_labels']).cuda().long()\n",
    "\n",
    "            case \"multiple points\":\n",
    "                input_point,input_label=utils.generate_random_points_polygon(geo)\n",
    "            \n",
    "            case \"multiple points + single point\":\n",
    "                input_point,input_label=utils.generate_random_points_polygon(geo,flag=\"rep\")\n",
    "\n",
    "            case \"multiple points + negative points\":\n",
    "                input_point,input_label=utils.generate_random_points_polygon(geo,flag=\"negative\")\n",
    "           \n",
    "            #creating boxes\n",
    "            case \"box\":\n",
    "                input_boxes=[]\n",
    "                flag=1\n",
    "                ##for georeferenced polygons\n",
    "                mask=utils.convert_polygon_to_mask_batch_transform(geo,(1024,1024),transform=transform)\n",
    "                tile_boxes=utils.create_boxes(mask,shapefile=False)\n",
    "               \n",
    "                # tile_boxes=utils.create_boxes(geo,shapefile=False)\n",
    "                input_boxes=torch.tensor(tile_boxes).cuda()\n",
    "            case \"box + single point\":\n",
    "                input_boxes=[]   \n",
    "                tile_boxes=utils.create_boxes(geo)\n",
    "                input_boxes=torch.tensor(tile_boxes).cuda()\n",
    "                input_point,input_label=utils.create_list_points(geo,name)\n",
    "\n",
    "            case \"box + multiple points\":\n",
    "                input_boxes=[]\n",
    "                tile_boxes=utils.create_boxes(geo)\n",
    "                input_boxes=torch.tensor(tile_boxes).cuda()\n",
    "                input_point,input_label=utils.generate_random_points_polygon(geo)\n",
    "\n",
    "            case _:\n",
    "                print(\"no or wrong prompt entered\")\n",
    "                \n",
    "        image_data_transpose=image_data.transpose(1,2,0)\n",
    "        print(image_data_transpose.shape)\n",
    "        print(image_data_transpose.shape[:2])\n",
    "        # x = torch.from_numpy(image.transpose(2, 0, 1)).float().cuda()\n",
    "        # pred_mask=sam.predictSAM(x=x,image=image,input_point=input_point,input_label=input_label,input_boxes=input_boxes,flag=flag)\n",
    "        x = torch.from_numpy(image_data).float().cuda()\n",
    "        pred_mask=sam.predictSAM(x=x,image=image_data_transpose,input_point=input_point,input_label=input_label,input_boxes=input_boxes,flag=flag)\n",
    "        os.makedirs(score_dir, exist_ok=True)\n",
    "        os.makedirs(output_dir + \"/\" + f\"{name}\", exist_ok=True)\n",
    "        \n",
    "        utils.save_shp(pred_mask,name,output_dir,image_data_transpose.shape[:2],image_data_transpose,tile_boxes)\n",
    "        \n",
    "    #     scores.micro_match_iou(pred_mask,name,gt,score_list,image,input_point,input_label,tile_boxes,geo=geo)\n",
    "    # scores.macro_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0hmealy7o2d"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "checkpoint=\"/home/jamada/jupyterlab/models/sam_vit_h_4b8939.pth\"\n",
    "images = \"data/images_fragmented/n1\"\n",
    "# orig_shp=\"data/pred_shapefile\"\n",
    "# skeleton_points=\"data/points.json\"\n",
    "pred = \"data/fragmented_shapefiles_n1_1024/n1\"\n",
    "output_dir = \"data/output\"\n",
    "\n",
    "score_dir = \"data/scores\"\n",
    "\n",
    "\n",
    "#get Multiclass Unet initial results\n",
    "# Calculate_CNN_Results()\n",
    "\n",
    "#loading SAM Model\n",
    "sam=SAM(checkpoint)\n",
    "\n",
    "#load Multiclass Unet CNN prediction file\n",
    "# ff = gpd.read_file(pred)\n",
    "\n",
    "#Run SAM prediction with box prompt\n",
    "main(CNN=\"multiclassUnet\",prompt_type=\"box\",sam=sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('data/images/n1.tif')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "with rasterio.open('data/images/n1.tif') as src:\n",
    "    image_data = src.read()\n",
    "\n",
    "# print(\"image\",image.shape)\n",
    "# image=image.transpose(2, 0, 1)\n",
    "# print(\"after image\",image.shape)\n",
    "print(\"beforeraster\",image_data.shape)\n",
    "image_data=image_data.transpose(1,2,0)\n",
    "print(\"raster\",image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X3LU3_oN9S8"
   },
   "outputs": [],
   "source": [
    "#for D-linkNet model\n",
    "pred = \"data/DCNN_pred_shapefile\"\n",
    "sam=SAM(checkpoint)\n",
    "main(CNN=\"DCNN\",prompt_type=\"box\",sam=sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Path to the georeferenced image file (replace with your actual file path)\n",
    "image_path = 'data/images/n1_0.tif'\n",
    "\n",
    "# Open the georeferenced image\n",
    "with rasterio.open(image_path) as src:\n",
    "    # Read the image data\n",
    "    image_data = src.read()\n",
    "\n",
    "    # Get image metadata\n",
    "    metadata = src.meta\n",
    "\n",
    "# Display the image using rasterio's plotting capabilities\n",
    "show(image_data, transform=metadata['transform'])\n",
    "\n",
    "print(\"Print metadata\")\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data/n1.zip -d data/n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "urbanmodels_venv",
   "language": "python",
   "name": "urbanmodels_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
