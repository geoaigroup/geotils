{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geoaigroup/geotils/blob/main/ToBeChecked/Demo_SAMGhandour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMt23BhFL5La"
      },
      "source": [
        "## SAM Online Demo: Segment everything Mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "644532a8"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07fabfee"
      },
      "source": [
        "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z3MWlXeRqbHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!git clone https://github.com/facebookresearch/segment-anything\n",
        "%cd /content/segment-anything\n",
        "!pip install -e .\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "CJdWU3inqwLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "mpD6G0w6tvp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69b28288"
      },
      "outputs": [],
      "source": [
        "#Necessary imports and helper functions for displaying points, boxes, and masks.\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import geopandas as gpd\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import shapely.geometry as sg\n",
        "from shapely import affinity\n",
        "from shapely.geometry import Point, Polygon\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "from shapely.geometry import shape\n",
        "\n",
        "#from metrics import DiceScore,IoUScore\n",
        "import pandas as pd\n",
        "import gc\n",
        "import shutil\n",
        "import fiona\n",
        "import json\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/\")\n",
        "from evaluate import cal_scores, matching_algorithm\n",
        "import SAMutils as utils\n",
        "from pred_SAM import SAM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6yDAdyql7lf"
      },
      "outputs": [],
      "source": [
        "def cal_score(gt_tile, pred_tile):\n",
        "    matcher = matching_algorithm(gt_tile, pred_tile)\n",
        "    iou_list, f1_scores, tp_pred_indices, tp_gt_indices, fp_indices, fn_indices, mscores, precision, recall = matcher.matching()\n",
        "    tp_iou_list, avg_tp_iou = matcher.tp_iou(tp_pred_indices, tp_gt_indices)\n",
        "    score = {}\n",
        "    scores_b = []\n",
        "    score['iou_list'] = iou_list\n",
        "    score['f1_scores'] = f1_scores\n",
        "    score['tp_iou_list'] = tp_iou_list\n",
        "    score['fp_indices'] = fp_indices\n",
        "    score['fn_indices'] = fn_indices\n",
        "    score['Mean_iou'] = np.mean(iou_list, dtype=float)\n",
        "    score['Mean_f1'] = np.mean(f1_scores, dtype=float)\n",
        "    score['avg_tp_iou'] = float(avg_tp_iou) if avg_tp_iou != None else 0.0\n",
        "    score['precision'] = precision\n",
        "    score['recall'] = recall\n",
        "\n",
        "    for s in mscores:\n",
        "        scores_b.append(s)\n",
        "    scores_b.append(score)\n",
        "\n",
        "    gtmask=np.zeros((512,512))\n",
        "    predmask=np.zeros((512,512))\n",
        "    for g in gt_tile:\n",
        "        gtmask=g+gtmask\n",
        "    for p in pred_tile:\n",
        "        predmask=p+predmask\n",
        "    fig,ax = plt.subplots(1,2,figsize = (10,10))\n",
        "    ax = ax.ravel()\n",
        "    ax[0].imshow(gtmask)\n",
        "    ax[0].set_title(\"GT\")\n",
        "    ax[1].imshow(predmask)\n",
        "    ax[1].set_title(\"MultiClassUnet CNN\")\n",
        "    plt.show()\n",
        "\n",
        "    return scores_b\n",
        "\n",
        "def Calculate_CNN_Results():\n",
        "    ff = gpd.read_file(pred)\n",
        "    score_list = []\n",
        "\n",
        "    ids = [f for f in os.listdir(orig_shp)]\n",
        "\n",
        "    for name in tqdm(ids):\n",
        "        print(name)\n",
        "        if glob.glob(score_dir + \"/\" + name + \"_score.json\" ):\n",
        "            print(\"Found\")\n",
        "            continue\n",
        "        if name in os.listdir(orig_shp):\n",
        "            try:\n",
        "                gt = gpd.read_file(orig_shp + \"/\" + name)\n",
        "                if len(gt[\"geometry\"]) == 0:\n",
        "                    continue\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "        predic = ff.loc[ff[\"ImageId\"] == name]\n",
        "        n=name.split('.')[0]\n",
        "        if len(predic[\"geometry\"]) == 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        gt_tile = []\n",
        "        pred_tile=[]\n",
        "\n",
        "        gt_tile=utils.convert_polygon_to_mask_batch(gt['geometry'])\n",
        "        pred_tile=utils.convert_polygon_to_mask_batch(predic[\"geometry\"])\n",
        "\n",
        "        scores_res=cal_score(gt_tile, pred_tile)\n",
        "        os.makedirs(score_dir, exist_ok=True)\n",
        "\n",
        "        with open(score_dir + f'/{name}_score.json', 'w') as f1:\n",
        "            json.dump(scores_res, f1)\n",
        "\n",
        "    scores=cal_scores(output_dir,score_dir)\n",
        "    scores.macro_score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P4w6hjqqNDl"
      },
      "outputs": [],
      "source": [
        "def main(image, pred_poly):\n",
        "    # score_list = []\n",
        "    # scores=cal_scores(output_dir,score_dir)\n",
        "    # # ff = gpd.read_file(pred)\n",
        "    # ids = [f for f in os.listdir(orig_shp)]\n",
        "\n",
        "    # print(name)\n",
        "    # print(\"Checking\")\n",
        "    flag=0\n",
        "    #predic = gpd.read_file(\"data/pred_shapefile/n1_regularized/n1_regularized.shp\")\n",
        "    #geo = predic[\"geometry\"]\n",
        "    geo = pred_poly\n",
        "\n",
        "    tile_boxes = []\n",
        "    input_point=None\n",
        "    input_label=None\n",
        "    input_boxes=None\n",
        "\n",
        "    input_boxes=[]\n",
        "    flag=1\n",
        "    tile_boxes=utils.create_boxes(geo)\n",
        "    input_boxes=torch.tensor(tile_boxes).cuda()\n",
        "\n",
        "    x = torch.from_numpy(image.transpose(2, 0, 1)).float().cuda()\n",
        "    pred_mask=sam.predictSAM(x=x,image=image,input_point=input_point,input_label=input_label,input_boxes=input_boxes,flag=flag)\n",
        "    #os.makedirs(score_dir, exist_ok=True)\n",
        "    #os.makedirs(output_dir + \"/\" + f\"{name}\", exist_ok=True)\n",
        "\n",
        "    #scores.micro_match_iou(pred_mask,name,gt,score_list,image,input_point,input_label,tile_boxes,geo=geo)\n",
        "    return pred_mask\n",
        "    #scores.macro_score()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YggfDICNqNDl"
      },
      "outputs": [],
      "source": [
        "import rasterio as rio\n",
        "from old_utils import *    #not using the latets version with onnx\n",
        "import sys\n",
        "sys.path.append(\"/content/segment-anything\")\n",
        "\n",
        "in_dir = \"/content/drive/MyDrive/\"\n",
        "out_dir = r'/content/results'\n",
        "checkpoint=\"/content/sam_vit_h_4b8939.pth\"\n",
        "\n",
        "sam=SAM(checkpoint)\n",
        "\n",
        "DOWN_SAMPLING=3\n",
        "\n",
        "directory = os.fsencode(in_dir)\n",
        "\n",
        "for file in os.listdir(directory):\n",
        "    filename = os.fsdecode(file)\n",
        "    if filename.endswith(\".tif\"):\n",
        "        #tiff_path = '../results/MAPSGEO/Meriata/Meriata_2022_06_28.tif'\n",
        "\n",
        "        raster_file = rio.open(f'{in_dir}/{filename}')\n",
        "        full_img = raster_file.read([1,2,3]).transpose(1,2,0)\n",
        "\n",
        "        #ff = gpd.read_file(pred)\n",
        "\n",
        "        mask_geotif = rio.open(f'/content/results_n0.tif')\n",
        "        predic_mask = mask_geotif.read()[0]#.transpose(1,2,0)\n",
        "\n",
        "        HEIGHT_orig, WIDTH_orig = full_img.shape[:2]\n",
        "        full_img = cv2.resize(full_img, (WIDTH_orig//DOWN_SAMPLING, HEIGHT_orig//DOWN_SAMPLING))\n",
        "\n",
        "        #Use below for gray images only\n",
        "        #full_img = raster_file.read().transpose(1,2,0)[:,:,0]\n",
        "        #full_img = cv2.cvtColor(full_img,cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        full_img, rrp_info = ratio_resize_pad(full_img, ratio = None, div=1024)\n",
        "        full_predic_mask, mask_rrp_info = ratio_resize_pad(predic_mask, ratio = None, div=1024)\n",
        "\n",
        "\n",
        "\n",
        "        #patching and running model\n",
        "        PATCH_SIZE = 1024\n",
        "        STRIDE_SIZE = 512\n",
        "        #CROP_SIZE = 768\n",
        "\n",
        "        HEIGHT, WIDTH = full_img.shape[:2]\n",
        "\n",
        "\n",
        "        full_mask = np.zeros((HEIGHT, WIDTH), dtype=np.float32)\n",
        "        full_mask[...] = np.nan\n",
        "\n",
        "        a = 0\n",
        "        M = 0\n",
        "        for hs in tqdm(range(a,HEIGHT,STRIDE_SIZE)):\n",
        "\n",
        "            for ws in range(a,WIDTH,STRIDE_SIZE):\n",
        "\n",
        "                he = hs+PATCH_SIZE\n",
        "                we = ws+PATCH_SIZE\n",
        "                patch = full_img[hs:he,ws:we,:]\n",
        "                patch_mask = full_predic_mask[hs:he,ws:we]\n",
        "\n",
        "                shapes = rasterio.features.shapes(patch_mask)\n",
        "                # read the shapes as separate lists\n",
        "                geometry = []\n",
        "                for shapedict, value in shapes:\n",
        "                    if value == 0:\n",
        "                        continue\n",
        "                    geometry.append(shape(shapedict))\n",
        "\n",
        "                # build the gdf object over the two lists\n",
        "                patch_gdf = gpd.GeoDataFrame({'geometry': geometry})\n",
        "                if len(patch_gdf) == 0:\n",
        "                    full_mask[hs:he,ws:we] = 0\n",
        "                else:\n",
        "                    with torch.no_grad():\n",
        "                        y_pred = main(patch,patch_gdf)\n",
        "\n",
        "\n",
        "                    y_pred = y_pred.detach().cpu().long().numpy()[:,0,:,:].astype(np.int16)\n",
        "\n",
        "                    n_patch,_,_ = y_pred.shape\n",
        "                    b_ids = np.arange(n_patch) + 1\n",
        "                    b_ids = b_ids[:,np.newaxis,np.newaxis]\n",
        "\n",
        "                    y_pred_mask = (y_pred.copy().sum(axis=0) > 0).astype(np.int16)\n",
        "                    y_pred *= b_ids\n",
        "                    y_pred = y_pred.max(axis=0) + M*y_pred_mask\n",
        "                    M = y_pred.max()\n",
        "                    full_mask[hs:he,ws:we] = y_pred\n",
        "\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "\n",
        "        # results = (\n",
        "        #         {\n",
        "        #     'properties': {'id': v}, 'geometry': s}\n",
        "        #         for i, (s, v)\n",
        "        #         in enumerate(\n",
        "        #             shapes(full_mask.astype(np.uint16), mask=None, transform=raster_file.transform)) if v!=0)\n",
        "        # #gdf = gpd.GeoDataFrame.from_features(list(results))\n",
        "        # #gdf = gdf.dissolve(by='id')\n",
        "        # gdf = gpd.GeoDataFrame.from_features(list(results),crs=raster_file.crs)\n",
        "        # gdf = gdf.dissolve(by='id')\n",
        "        # gdf.to_file(f'{out_dir}/{filename}')\n",
        "\"\"\"\n",
        "        ##post_process\n",
        "        thresh = 0.5\n",
        "        h,w = full_mask.shape[:2]\n",
        "        t,b,l,r = rrp_info['pads']\n",
        "        orig_size = rrp_info['orig_size']\n",
        "\n",
        "        full_mask = full_mask[t:h-b,l:w-r,:]\n",
        "        full_mask = cv2.resize(full_mask,(WIDTH_orig, HEIGHT_orig))    #used if downsampling is needed\n",
        "        print(full_mask.shape)\n",
        "        instances = post_process(full_mask,thresh = thresh,thresh_b = 0.5,mina=100,mina_b=50)\n",
        "\n",
        "        #to shapefile\n",
        "        results = (\n",
        "                {\n",
        "            'properties': {'id': v}, 'geometry': s}\n",
        "                for i, (s, v)\n",
        "                in enumerate(\n",
        "                    shapes(instances.astype(np.uint16), mask=None, transform=raster_file.transform)) if v!=0)\n",
        "        #gdf = gpd.GeoDataFrame.from_features(list(results))\n",
        "        #gdf = gdf.dissolve(by='id')\n",
        "        gdf = gpd.GeoDataFrame.from_features(list(results),crs=raster_file.crs)\n",
        "        gdf = gdf.dissolve(by='id')\n",
        "        gdf.to_file(f'{out_dir}/{filename}')\n",
        "\"\"\"\n",
        "                #plt.imshow(y_pred)\n",
        "                #break\n",
        "                #patch_mask = y_pred[0,...].cpu().numpy().transpose(1,2,0)\n",
        "                #full_mask_patch = full_mask[hs:he,ws:we].copy()\n",
        "                # print(patch_mask.shape)\n",
        "                # print(full_mask.shape)\n",
        "                # print(full_mask_patch.shape)\n",
        "\n",
        "                #full_mask_patch = np.stack([full_mask_patch,patch_mask])\n",
        "                #full_mask[hs:he,ws:we] = np.nanmean(full_mask_patch,axis=0)\n",
        "            #break\n",
        "        #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h,w = full_mask.shape[:2]\n",
        "t,b,l,r = rrp_info['pads']\n",
        "orig_size = rrp_info['orig_size']\n",
        "\n",
        "full_mask = full_mask[t:h-b,l:w-r]"
      ],
      "metadata": {
        "id": "FMflz7K4yFT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shapes = rasterio.features.shapes(full_mask, mask=None, transform=raster_file.transform)\n",
        "# read the shapes as separate lists\n",
        "geometry = []\n",
        "for shapedict, value in shapes:\n",
        "    if value == 0:\n",
        "        continue\n",
        "    geometry.append(shape(shapedict))\n",
        "\n",
        "# build the gdf object over the two lists\n",
        "full_gdf = gpd.GeoDataFrame({'geometry': geometry}, crs=raster_file.crs)\n",
        "#gdf = gpd.GeoDataFrame.from_features(list(results),\n",
        "\n",
        "#gdf = gdf.dissolve(by='id')\n",
        "full_gdf.to_file(f'{out_dir}/{filename}')"
      ],
      "metadata": {
        "id": "z45_wF_wy1if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_bPKB2GqNDm"
      },
      "outputs": [],
      "source": [
        "5/0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "urbanmodels_venv",
      "language": "python",
      "name": "urbanmodels_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}